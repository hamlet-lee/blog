# cut 使用示例：读取配置文件中某一项
```shell
executorport=`cat $yanagishima_dir/conf/yanagishima.properties | grep executor.port | cut -d = -f 2`
```

# yanagishima 连接 presto-gateway 容易发生超时的问题
```
2019/05/16 22:36:46.312 +0800 ERROR [PrestoAsyncServlet] [Yanagishima] java.net.SocketTimeoutException: timeout
java.io.UncheckedIOException: java.net.SocketTimeoutException: timeout
	at com.facebook.presto.client.JsonResponse.execute(JsonResponse.java:148)
	at com.facebook.presto.client.StatementClient.<init>(StatementClient.java:125)
	at yanagishima.service.PrestoServiceImpl.getStatementClient(PrestoServiceImpl.java:350)
	at yanagishima.service.PrestoServiceImpl.doQueryAsync(PrestoServiceImpl.java:81)
	at yanagishima.servlet.PrestoAsyncServlet.lambda$doPost$0(PrestoAsyncServlet.java:82)
	at java.util.Optional.ifPresent(Optional.java:159)
	at yanagishima.servlet.PrestoAsyncServlet.doPost(PrestoAsyncServlet.java:48)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287)
	at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277)
	at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182)
	at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)
	at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)
	at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)
	at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668)
	at yanagishima.filter.YanagishimaFilter.doFilter(YanagishimaFilter.java:38)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:224)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119)
	at org.eclipse.jetty.server.Server.handle(Server.java:517)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketTimeoutException: timeout
	at okio.Okio$4.newTimeoutException(Okio.java:230)
	at okio.AsyncTimeout.exit(AsyncTimeout.java:285)
	at okio.AsyncTimeout$2.read(AsyncTimeout.java:241)
	at okio.RealBufferedSource.indexOf(RealBufferedSource.java:345)
	at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:217)
	at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:211)
	at okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:187)
	at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:88)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:125)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200)
	at okhttp3.RealCall.execute(RealCall.java:77)
	at com.facebook.presto.client.JsonResponse.execute(JsonResponse.java:130)
	... 40 more
Caused by: java.net.SocketException: Socket closed
	at java.net.SocketInputStream.read(SocketInputStream.java:203)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at okio.Okio$2.read(Okio.java:139)
	at okio.AsyncTimeout$2.read(AsyncTimeout.java:237)
	... 60 more
```
开始以为是因为timeout。但后来发现“Socket closed”的字样。  
这说明，可能是因为一个connection已经被对方或者操作系统关闭，但是这边还在使用才造成的。  
参考下面资料可能能够解决：
  1. 参考： https://www.jianshu.com/p/8e7f0a3a3489
  1. https://github.com/square/okhttp/issues/190 这里说，默认 keep alive 是 5分钟。
  1. https://github.com/square/okhttp/issues/2031 这里说，可以用如下方式取消keep alive
     ```
     okHttpClient.setConnectionPool(new ConnectionPool(0, 0));
     ```
可能是被集群的什么默认配置害了，5分钟可能是过长的。  
看看能不能设置为5秒，或者取消keep alive试试。  
修改代码后，问题依然存在，可能不是keep alive的问题。  

接下来，尝试在单独的presto-gateway上做测试，以期重现问题。  

单独部署一个gateway-yana，然后yanagishima走gateway-yana。
过了15分钟左右，成功复现timeout。  
在gateway-yana日志中，发现
```
DEBUG [2019-05-23 06:16:22,064] com.lyft.data.proxyserver.ProxyImpl.Proxly: 1663081801 rewriting: http://mylocalhost:232xx/v1/statement -> http://myhost-to:282xx/v1/statement
INFO  [2019-05-23 06:16:22,064] com.lyft.data.gateway.handler.QueryIdCachingProxyHandler: Processing request endpoint: [/v1/statement], payload: [---SQL内容省略

  
]
DEBUG [2019-05-23 06:16:22,064] com.lyft.data.proxyserver.ProxyImpl.Proxly: 1663081801 proxying to upstream:
POST /v1/statement HTTP/1.1
User-Agent: StatementClient/0.192
Connection: keep-alive
X-Presto-Source: yanagishima
Host: mylocalhost:232xx
Accept-Encoding: gzip
X-Presto-Language: en-US
X-Presto-User: xxx
X-Presto-Transaction-Id: NONE
X-Presto-Time-Zone: PRC
X-Presto-Catalog: hive
X-Presto-Schema: default
Content-Length: 3044
Content-Type: application/json; charset=UTF-8
proxytarget: http://myhost-to:282xx

HttpRequest[POST /v1/statement HTTP/1.1]@50222e74

DEBUG [2019-05-23 06:16:22,068] com.lyft.data.proxyserver.ProxyImpl.Proxly: 1663081801 proxying content to upstream: 3004 bytes
DEBUG [2019-05-23 06:16:52,068] com.lyft.data.proxyserver.ProxyImpl.Proxly: 1663081801 proxying failed
! java.util.concurrent.TimeoutException: Idle timeout 30000 ms
! at org.eclipse.jetty.client.http.HttpConnectionOverHTTP.onIdleExpired(HttpConnectionOverHTTP.java:145)
! at org.eclipse.jetty.io.AbstractEndPoint.onIdleExpired(AbstractEndPoint.java:401)
! at org.eclipse.jetty.io.IdleTimeout.checkIdleTimeout(IdleTimeout.java:166)
! at org.eclipse.jetty.io.IdleTimeout$1.run(IdleTimeout.java:50)
! at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
! at java.util.concurrent.FutureTask.run(FutureTask.java:266)
! at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
! at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
! at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
! at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
! at java.lang.Thread.run(Thread.java:745)
DEBUG [2019-05-23 06:16:52,069] com.lyft.data.proxyserver.ProxyImpl.Proxly: 1663081801 proxying complete
```
可见，明确的是gateway收到了查询，但proxy到上游出现问题。  
解决策略：
1. 减少 /v1/query 查询的量，以免上游服务压力太大
    * 实际上查询量并不大，但是请求方有connection leak。现已修复。
    * Gateway 的 QueryIdCachingProxyHandler.postConnectionHook() 在同一个Response的每批数据到来的时候，都会被调用一次。所以在DEBUG log里面，会多次看到类似如下的内容
    ```text
    DEBUG [2019-05-23 09:04:04,000] com.lyft.data.gateway.handler.QueryIdCachingProxyHandler: SKIPPING For /v1/query/20190523_090359_01959_wagkj
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.proxyserver.ProxyImpl.Proxly: [524723618] proxying content to downstream: [8680] bytes
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.gateway.handler.QueryIdCachingProxyHandler: SKIPPING For /v1/query/20190523_090359_01959_wagkj
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.proxyserver.ProxyImpl.Proxly: [524723618] proxying content to downstream: [11584] bytes
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.gateway.handler.QueryIdCachingProxyHandler: SKIPPING For /v1/query/20190523_090359_01959_wagkj
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.proxyserver.ProxyImpl.Proxly: [524723618] proxying content to downstream: [1448] bytes
    DEBUG [2019-05-23 09:04:04,022] com.lyft.data.gateway.handler.QueryIdCachingProxyHandler: SKIPPING For /v1/query/20190523_090359_01959_wagkj
    ...
    ```
1. 增大上面30000 ms timeout的设定
  * 这里又涉及到 jetty httpclient
  
* 关键发现： Content-Length: 3044 与 1663081801 proxying content to upstream: 3004 bytes 字节数不符合！见下面处理

# 非默认端口SCP
参见： https://stackoverflow.com/questions/10341032/scp-with-port-number-specified
```shell
scp -P 80 ... # Use port 80 to bypass the firewall, instead of the scp default
```

# ip 解析的性能调优
原始数据 1GB 左右，放到java堆中，占用接近10GB。如果用于MapReduce程序或者用于Hive Tez程序，都比较费内存。  
有没有比较好的方案？  
看了下解析代码的示例，发现似乎只是简单的二分搜索。  
所以，主要的问题就是用更节省内存的方式来存储了。  

* 方案1：仍然使用 Java On Heap 存储，但简化数据结构
    * 数据条目数：1000万行 即 10 M行。假设每个对应一个对象，每个对象需要32字节，则是 320 MB。
* 方案2：使用Off Heap方式，并且用内存映射方式。这样同一台机器的多个进程可以共享文件。
    * 调研1： 共享文件系统是否支持内存映射方式 
    * 调研2： YARN 检查 进程内存占用时，是否会将共享的部分也计入？
    * 调研3： 如何方便地操作 Off Heap，例如如何做二分查找？
* 方案3：JNI，C++实现


# Presto Gateway 的 upstream timeout处理
在 AbstractProxyServelet.java 中可以看到，读取了如下 Servlet属性
```java
        Executor executor;
        String value = config.getInitParameter("maxThreads");
        if (value == null || "-".equals(value))
        {
            executor = (Executor)getServletContext().getAttribute("org.eclipse.jetty.server.Executor");
            if (executor==null)
                throw new IllegalStateException("No server executor for proxy");
        }
        else
        {
            QueuedThreadPool qtp= new QueuedThreadPool(Integer.parseInt(value));
            String servletName = config.getServletName();
            int dot = servletName.lastIndexOf('.');
            if (dot >= 0)
                servletName = servletName.substring(dot + 1);
            qtp.setName(servletName);
            executor=qtp;
        }

        client.setExecutor(executor);

        value = config.getInitParameter("maxConnections");
        if (value == null)
            value = "256";
        client.setMaxConnectionsPerDestination(Integer.parseInt(value));

        value = config.getInitParameter("idleTimeout");
        if (value == null)
            value = "30000";
        client.setIdleTimeout(Long.parseLong(value));

        value = config.getInitParameter("timeout");
        if (value == null)
            value = "60000";
        _timeout = Long.parseLong(value);

        value = config.getInitParameter("requestBufferSize");
        if (value != null)
            client.setRequestBufferSize(Integer.parseInt(value));

        value = config.getInitParameter("responseBufferSize");
        if (value != null)
            client.setResponseBufferSize(Integer.parseInt(value));
```

其设置的位置是  
ProxyServer.java  
```java

    ServletHolder proxyServlet = new ServletHolder(config.getName(), proxy);

    proxyServlet.setInitParameter("proxyTo", config.getProxyTo());
    proxyServlet.setInitParameter("prefix", config.getPrefix());
    proxyServlet.setInitParameter("trustAll", config.getTrustAll());
    proxyServlet.setInitParameter("preserveHost", config.getPreserveHost());
    
    // 增加超时配置
    
    // 当upstream在指定时间内没有response，就会抛异常
    proxyServlet.setInitParameter("idleTimeout", "600000");
    
    // 暂时不确定用在哪，可能是按照Request.java中说的 the total timeout for the request/response conversation
    proxyServlet.setInitParameter("timeout", "600000");
```

ProxyServer.java 也有对downstream的配置，可以顺便也做修改
```java
    ServerConnector connector = new ServerConnector(server);
    connector.setHost("0.0.0.0");
    connector.setPort(config.getLocalPort());
    connector.setName(config.getName());
    connector.setAccepting(true);
    
    // 增加这个
    connector.setIdleTimeout(60000);
```

# Presto-gateway 对 POST 的 Body 处理不当的问题
Content-Length: 3044 与 1663081801 proxying content to upstream: 3004 bytes 字节数不符合！  
Content-Length > 实际上传的字节数 -> 这会导致upstream一直在等待数据！  

查看 MultiReadHttpServletRequest.java，
```java
public MultiReadHttpServletRequest(HttpServletRequest request) throws IOException {
    super(request);
    StringBuffer sb = new StringBuffer("");
    BufferedReader bufferedReader = request.getReader();
    String line;
    while ((line = bufferedReader.readLine()) != null) {
      sb.append(line);
      sb.append("\n");  -- 这里只加了'\n'
    }
    body = sb.toString();
  }


  @Override
  public ServletInputStream getInputStream() throws IOException {
    final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(body.getBytes()); -- 这里从String重新构造
    return new ServletInputStream() {
      @Override
      public boolean isFinished() {
        return false;
      }

      @Override
      public boolean isReady() {
        return false;
      }

      @Override
      public void setReadListener(ReadListener readListener) {}

      public int read() throws IOException {
        return byteArrayInputStream.read();
      }
    };
  }
```

