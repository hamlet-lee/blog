# 部署一个HiveServer，用于测试自定义的SerDe代码
1. rsync 到测试机器  
   参考脚本 rsync_hive.sh
   ```shell
    #!/bin/sh
    export TO_HOST=$1
    if [ "" == "$TO_HOST" ]; then
      echo "args: <TO_HOST>"
      exit 1
    fi

    rsync -avP hadoop-2.7.2 jdk1.8.0_144 jdk1.8.0_40 apache-tez-0.8.4-bin apache-hive-2.3.0-bin --exclude=*/logs/* --exclude=*/log/* --exclude=*/tmp/* $TO_HOST:`pwd`

   ```
1. 调整配置，服务不进入ha集群  
   相关配置可以参考
   ```xml
     <property>
       <name>hive.server2.support.dynamic.service.discovery</name>
       <value>false</value>
       <description>Whether HiveServer2 supports dynamic service discovery for its clients. To support this, each instance of HiveServer2 currently uses ZooKeeper to register itself, when it is brought up. JDBC/ODBC clients should use the ZooKeeper ensemble: hive.zookeeper.quorum in their connection string.</description>
     </property>
   ```

1. conf/hive-env.sh 参考
   ```shell
   export JAVA_HOME=/path/to/jdk1.8.0_40
   export HADOOP_HOME=/path/to/hadoop-2.7.2
   export HADOOP_CONF_DIR=/path/to/share/hadoop-conf
   export HIVE_HOME=/path/to/apache-hive-2.3.0-bin

   # Hive Configuration Directory can be controlled by:
   # export HIVE_CONF_DIR=
   export HIVE_CONF_DIR=/path/to/apache-hive-2.3.0-bin/conf

   # Folder containing extra ibraries required for hive compilation/execution can be controlled by:
   # export HIVE_AUX_JARS_PATH=

   # 这里的变量是配置给HiveServer使用的
   # MY_CONF_DIR 是自定义的系统变量，用于指定配置文件存放信息。SerDe中会读取
   # java.io.tmpdir 这个指定临时目录，避免/tmp满；HiveServer 的一些临时文件会放在这个目录中
   # -Xmx25000m ： HiveServer 的 JVM Heap 配置。太小的话，并发查询多会出问题。
   export HADOOP_CLIENT_OPTS="-DMY_CONF_DIR=/path/to/my/conf -Djava.io.tmpdir=/path/to/tmp -Xmx25000m"

   export TEZ_CONF_DIR=/path/to/apache-tez-0.8.4-bin/conf
   export TEZ_JARS=/path/to/apache-tez-0.8.4-bin
   export HADOOP_CLASSPATH=${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*:
   ```
1. 注意还要保证自定义的 SerDe 和 UDF 等默认能够。因此写如下启动脚本 /path/to/init-conf/.hiverc
   ```sql
   set role admin;
   set hive.mapred.mode = strict;
   set hive.limit.query.max.table.partition=32;
   -- SerDe 的 jar 包和进一步的依赖，在调试阶段可以放在这里；一旦上线，可以移到下面 start_hiveserver.sh 中
   -- add jar /path/to/my-serde.jar
   -- add jar /path/to/dependency1.jar
   -- add jar /path/to/dependency2.jar
   -- ...

   add jar /path/to/repo/com/epam/original-date-range-1.0.jar;
   add jar /path/to/repo/com/my-test/my-udf-1.0.test32.jar;

   -- UDFs
   create temporary function date_range as 'com.epam.hive.udf.DateRange';
   
   create temporary function data2fsketch as 'com.yahoo.sketches.hive.frequencies.DataToStringsSketchUDAF';
   create temporary function unionf as 'com.yahoo.sketches.hive.frequencies.UnionStringsSketchUDAF';
   create temporary function get_fitems as 'com.yahoo.sketches.hive.frequencies.GetFrequentItemsFromStringsSketchUDTF';

   create temporary function data2sketch as 'com.yahoo.sketches.hive.theta.DataToSketchUDAF';
   create temporary function unions as 'com.yahoo.sketches.hive.theta.UnionSketchUDAF';
   create temporary function estimate as 'com.yahoo.sketches.hive.theta.EstimateSketchUDF';
   create temporary function diffs as 'com.yahoo.sketches.hive.theta.ExcludeSketchUDF';
   create temporary function intersects as 'com.yahoo.sketches.hive.theta.IntersectSketchUDF';

   create temporary function data2sketchq as 'com.yahoo.sketches.hive.quantiles.DataToDoublesSketchUDAF';
   create temporary function getQuantile as 'com.yahoo.sketches.hive.quantiles.GetQuantileFromDoublesSketchUDF';
   create temporary function getPmf as 'com.yahoo.sketches.hive.quantiles.GetPmfFromDoublesSketchUDF'; 

   set hive.tez.container.size=4000;
   
   -- 传递给Tez任务的命令行
   set hive.tez.java.opts = -DMY_CONF_DIR=/path/to/conf -Xms1200m -Xmx1200m -XX:+PrintGCDetails -verbose:gc -XX:+UseNUMA -XX:+UseParallelGC;
   set tez.runtime.io.sort.mb=100;
   set hive.auto.convert.join.noconditionaltask.size=600;
   set hive.exec.dynamic.partition=true;
   set hive.exec.dynamic.partition.mode=nonstrict;
   set hive.exec.max.dynamic.partitions=2000;
   set mapred.reduce.tasks = 32;
   set hive.optimize.index.filter=true;
   set tez.am.resource.memory.mb = 6000;
   set tez.am.launch.cmd-opts=-Xmx4000m;
   set hive.vectorized.execution.enabled = true;
   set hive.exec.pre.hooks=;
   set tez.queue.name = my_default_queue;
   -- set hive.tez.auto.reducer.parallelism = true;
   set tez.grouping.min-size=268435456;
   set tez.grouping.max-size=1073741824;
   -- 2 hours
   set mapred.task.timeout=7200000;
   set role public;
   ```  
   这个文件，要按照hive-site.xml中配置的位置放置
   ```xml
     <property>
       <name>hive.server2.global.init.file.location</name>
       <value>/path/to/init-conf</value>
       <description>
         Either the location of a HS2 global init file or a directory containing a .hiverc file. If the
         property is set, the value must be a valid path to an init file or directory where the init file is located.
       </description>
     </property>
   ```
1. 启动脚本参考  bin/start_hiveserver.sh
   ```shell
   #!/bin/sh
   export TEZ_CONF_DIR=/path/to/apache-tez-0.8.4-bin/conf
   export TEZ_JARS=/path/to/apache-tez-0.8.4-bin
   export HADOOP_CLASSPATH=${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*:
   export HIVE_DEBUG_PORT=12333
   export HIVE_DEBUG="-Xdebug -Xrunjdwp:transport=dt_socket,address=${HIVE_DEBUG_PORT},server=y,suspend=n"
   #export HADOOP_CLIENT_OPTS="-Xmx2000m"


   export HIVE_AUX_JARS_PATH=/global/home/analysis/hadoop-4mc-2.0.0-2.0.0.jar:/disk1/eadop/apache-hive-2.3.0-bin/hcatalog/share/hcatalog/hive-hcatalog-core-2.3.0.jar:/path/to/my-serde.jar
   
   # 带调试启动，放到后台
   nohup bin/hiveserver2 --debug 2>&1 1>log/hiveserver2.log &
   
   # 带调试启动，在前台
   # bin/hiveserver2 --debug 
   ```

1. 启动后，标准输入输出只有少量日志。更多日志见： /path/to/apache-hive-2.3.0-bin/tmp/${USER}/hive.log

1. Beeline 的 启动脚本  
   参考：xxx_hive.sh
   ```shell
   #!/bin/sh
   echo JAVA_HOME=$JAVA_HOME
   echo PATH=$PATH
   echo CLASSPATH=$CLASSPATH
   echo HADOOP_CLASSPATH=$HADOOP_CLASSPATH
   echo HADOOP_HOME=$HADOOP_HOME
   echo HADOOP_OPTS=$HADOOP_OPTS

   export HIVE_HOME=/path/to/shared/apache-hive-2.3.0-bin
   pushd /path/to/shared/apache-hive-2.3.0-bin
   bin/start_beeline_xxx.sh $*

   ```
   

1. Beeline 的 内层启动脚本  
   参考：/path/to/shared/apache-hive-2.3.0-bin/bin/start_beeline_xxx.sh
   ```shell
   #!/bin/sh
   if [ "$HIVE_USER" == "" ]; then
     export HIVE_USER=`whoami`
   fi
   bin/beeline -u jdbc:hive2://${YOUR_HIVESERVER_HOST}:${YOUR_HIVESERVER_PORT} -n $HIVE_USER $*
   ```  
   这里的 ${YOUR_HIVESERVER_PORT} 由hive-site.xml里面的  
   ```xml
     <property>
       <name>hive.server2.thrift.port</name>
       <value>10000</value>
       <description>Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.</description>
     </property>
   ```
   定义
