# 将表格转换为ORC格式，并使用bloomfilter
```sql
create table mydb.mytbl_orc stored as orc
TBLPROPERTIES (
  'orc.bloom.filter.write.version' = 'original',
  'orc.bloom.filter.columns' = 'username'
) 
as select * from mydb.mytbl sort by username
```
这里write.version=original, 可以写出UTF-8和ANSI两种格式的bloomfilter。presto只能识别ANSI格式的。

```shell
hive --orcfiledump /path/to/mydb.db/mytbl_orc/000000_0
```
这样可以查看到HDFS上一个ORC文件的metadata。

# presto的参数配置
https://teradata.github.io/presto/docs/current/admin/properties.html
https://teradata.github.io/presto/docs/141t/admin/tuning.html

```
optimizer.use-intermediate-aggregations
中间merge，approx_distinct的查询可能用得着

query.initial-hash-partitions
join使用的bucket数量，可能提高join、distinct uid 性能用得着

columnar_processing_dictionary
字典处理，可能runjs处理ORC时需要关掉
```

有关内存配置的一些说明（文档中可能漏掉了一些说明）
https://github.com/prestodb/presto/issues/11005

示例的配置,Xmx为35GB时
```properties
query.max-memory-per-node = 12GB
query.max-total-memory-per-node =15GB
memory.heap-headroom-per-node = 8G
```
如果没有恰当配置，可能报类似如下的错误
```
18) Error injecting constructor, java.lang.IllegalArgumentException: Invalid memory configuration. The sum of max total query memory per node (21474836480) and heap headroom (8053063680) cannot be larger than the available heap memory (26843545600)
```
