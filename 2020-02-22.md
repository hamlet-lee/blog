# Kudu 学习
* https://kudu.apache.org/overview.html

进一步可学习：
* https://kudu.apache.org/docs/schema_design.html
* https://kudu.apache.org/docs/kudu_impala_integration.html
* https://kudu.apache.org/kudu.pdf
* https://raft.github.io/
* https://pmem.io/

# Kafka to Kudu
* Plain Java
  * https://kudu.apache.org/apidocs/
* Lenses
  * https://lenses.io/architecture-and-integrations/
  * https://lenses.io/connect/kafka-to-kudu/
* Flume
  * [如何使用Flume采集Kafka数据写入Kudu](https://cloud.tencent.com/developer/article/1158194)
* Kafka Connect
  * https://github.com/onfocusio/kafka-connect-kudu http://kafka.apache.org/documentation.html#connect
* Flink
  * https://github.com/rubencasado/Flink-Kudu

# Doris
* Doris 与 Hive
  * 导出到HDFS http://doris.apache.org/documentation/cn/administrator-guide/export-manual.html#id2
* 使用建议 http://doris.apache.org/documentation/cn/getting-started/best-practice.html
  ```
  1.2 大宽表与 Star Schema
  业务方建表时, 为了和前端业务适配, 往往不对维度信息和指标信息加以区分, 而将 Schema 定义成大宽表。对于 Doris 而言, 这类大宽表往往性能不尽如人意:

  Schema 中字段数比较多, 聚合模型中可能 key 列比较多, 导入过程中需要排序的列会增加。
  维度信息更新会反应到整张表中，而更新的频率直接影响查询的效率。
  使用过程中，建议用户尽量使用 Star Schema 区分维度表和指标表。频繁更新的维度表也可以放在 MySQL 外部表中。而如果只有少量更新, 可以直接放在 Doris 中。在 Doris 中存储维度表时，可对维度表设置更多的副本，提升 Join 的性能。
  ```
* 从 Kafka 导入数据
http://doris.incubator.apache.org/documentation/cn/administrator-guide/load-data/routine-load-manual.html?highlight=kafka

* 后续规划 https://www.infoq.cn/article/vXup94ub59yA*k0tNeFE
```
优化存储引擎的格式：最早做的列存格式支持的压缩算法不够丰富，我们希望支持更多的压缩算法。

优化整个文件的组织格式：提升不同的压缩效果，这样一是可以减少 IO，二是可以在一个对资源或者对消费比较敏感的情况下，节省磁盘的带宽成本。

优化查询部分：就是目前正在做的一个就是基于 cost model 的一个优化

计算存储的分离：以便更好地适应整个云上的一个环境。
```

# Flink
* https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/getting-started/index.html
* https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/getting-started/docker-playgrounds/flink-operations-playground.html
* Table
  * https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/
  * https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/index.html
  * SQL Client
    * [官方 sqlClient 说明](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sqlClient.html)
    * https://www.jianshu.com/p/680970e7c2d9
  * Connect to external systems
    * https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/connect.html

# Docker compose 学习
* https://www.runoob.com/docker/docker-compose.html

注意 `build: .` 很好用？
```yaml
# yaml 配置
version: '3'
services:
  web:
    build: .
    ports:
     - "5000:5000"
  redis:
    image: "redis:alpine"
```

```
ulimits
覆盖容器默认的 ulimit。

ulimits:
  nproc: 65535
  nofile:
    soft: 20000
    hard: 40000
```

```
volumes
将主机的数据卷或着文件挂载到容器里。

version: "3.7"
services:
  db:
    image: postgres:latest
    volumes:
      - "/localhost/postgres.sock:/var/run/postgres/postgres.sock"
      - "/localhost/data:/var/lib/postgresql/data"
```

```
仅在 json-file 驱动程序下，可以使用以下参数，限制日志得数量和大小。

logging:
  driver: json-file
  options:
    max-size: "200k" # 单个文件大小为200k
    max-file: "10" # 最多10个文件
当达到文件限制上限，会自动删除旧得文件。
```

```
network_mode
设置网络模式。

network_mode: "bridge"
network_mode: "host"
network_mode: "none"
network_mode: "service:[service name]"
network_mode: "container:[container name/id]"
```

```
extra_hosts
添加主机名映射。类似 docker client --add-host。

extra_hosts:
 - "somehost:162.242.195.82"
 - "otherhost:50.31.209.229"
以上会在此服务的内部容器中 /etc/hosts 创建一个具有 ip 地址和主机名的映射关系：

162.242.195.82  somehost
50.31.209.229   otherhost
```

```
networks

配置容器连接的网络，引用顶级 networks 下的条目 。

services:
  some-service:
    networks:
      some-network:
        aliases:
         - alias1
      other-network:
        aliases:
         - alias2
networks:
  some-network:
    # Use a custom driver
    driver: custom-driver-1
  other-network:
    # Use a custom driver which takes special options
    driver: custom-driver-2
aliases ：同一网络上的其他容器可以使用服务名称或此别名来连接到对应容器的服务。
```

```
cap_add，cap_drop
添加或删除容器拥有的宿主机的内核功能。

cap_add:
  - ALL # 开启全部权限

cap_drop:
  - SYS_PTRACE # 关闭 ptrace权限
```

```
depends_on
设置依赖关系。

docker-compose up ：以依赖性顺序启动服务。在以下示例中，先启动 db 和 redis ，才会启动 web。
docker-compose up SERVICE ：自动包含 SERVICE 的依赖项。在以下示例中，docker-compose up web 还将创建并启动 db 和 redis。
docker-compose stop ：按依赖关系顺序停止服务。在以下示例中，web 在 db 和 redis 之前停止。
version: "3.7"
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres
注意：web 服务不会等待 redis db 完全启动 之后才启动。
```

# Flink playground

## 要先解决的问题：
* 虚拟机磁盘空间问题
https://blog.csdn.net/acdefghb/article/details/80103817
  * gparted
  * blkid
  * mkdir -p /disk1
  * /etc/fstab
    ```
    UUID=xxxx /disk1 ext4 defaults 0 0
    ```
  * docker root dir: https://www.cnblogs.com/atuotuo/p/7217331.html
    ```
    [root@centos var]# docker info | grep -i root
     Docker Root Dir: /var/lib/docker

    vi /etc/systemd/system/docker.service.d/docker.root.conf and populate with:
    [Service]
    ExecStart=
    ExecStart=/usr/bin/dockerd -g /new/docker/root -H fd://
    systemctl daemon-reload
    systemctl restart docker
    docker info - verify the root dir has updated
    Note - Existing Containers and Images
    If you already have containers or images in /var/lib/docker you may wish to stop and back these up before moving them to the new root location. Moving can be done by either rsync -a /var/lib/docker/* /path/to/new/root or if permissions do not matter, you can simply use mv or cp too.
    ```


playground
```shell
git clone --branch release-1.9 https://github.com/apache/flink-playgrounds.git
docker-compose build
docker-compose up -d

# list
docker-compose ps
                    Name                                  Command               State                   Ports
-----------------------------------------------------------------------------------------------------------------------------
operations-playground_clickevent-generator_1   /docker-entrypoint.sh java ...   Up       6123/tcp, 8081/tcp
operations-playground_client_1                 /docker-entrypoint.sh flin ...   Exit 0
operations-playground_jobmanager_1             /docker-entrypoint.sh jobm ...   Up       6123/tcp, 0.0.0.0:8081->8081/tcp
operations-playground_kafka_1                  start-kafka.sh                   Up       0.0.0.0:9094->9094/tcp
operations-playground_taskmanager_1            /docker-entrypoint.sh task ...   Up       6123/tcp, 8081/tcp
operations-playground_zookeeper_1              /bin/sh -c /usr/sbin/sshd  ...   Up       2181/tcp, 22/tcp, 2888/tcp, 3888/tcp

# shutdown
# docker-compose down -v

# logs
docker-compose logs -f jobmanager
docker-compose logs -f taskmanager

# CLI
docker-compose run --no-deps client flink --help

# Flink REST API
curl localhost:8081/jobs

# Kafka Topics
# //input topic (1000 records/s)
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic input
# //output topic (24 records/min)
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic output
```
