# Kudu 学习
* https://kudu.apache.org/overview.html

进一步可学习：
* https://kudu.apache.org/docs/schema_design.html
* https://kudu.apache.org/docs/kudu_impala_integration.html
* https://kudu.apache.org/kudu.pdf
* https://raft.github.io/
* https://pmem.io/

# Kafka to Kudu
* Plain Java
  * https://kudu.apache.org/apidocs/
* Lenses
  * https://lenses.io/architecture-and-integrations/
  * https://lenses.io/connect/kafka-to-kudu/
* Flume
  * [如何使用Flume采集Kafka数据写入Kudu](https://cloud.tencent.com/developer/article/1158194)
* Kafka Connect
  * https://github.com/onfocusio/kafka-connect-kudu http://kafka.apache.org/documentation.html#connect
* Flink
  * https://github.com/rubencasado/Flink-Kudu

# Doris
* Doris 与 Hive
  * 导出到HDFS http://doris.apache.org/documentation/cn/administrator-guide/export-manual.html#id2
* 使用建议 http://doris.apache.org/documentation/cn/getting-started/best-practice.html
  ```
  1.2 大宽表与 Star Schema
  业务方建表时, 为了和前端业务适配, 往往不对维度信息和指标信息加以区分, 而将 Schema 定义成大宽表。对于 Doris 而言, 这类大宽表往往性能不尽如人意:

  Schema 中字段数比较多, 聚合模型中可能 key 列比较多, 导入过程中需要排序的列会增加。
  维度信息更新会反应到整张表中，而更新的频率直接影响查询的效率。
  使用过程中，建议用户尽量使用 Star Schema 区分维度表和指标表。频繁更新的维度表也可以放在 MySQL 外部表中。而如果只有少量更新, 可以直接放在 Doris 中。在 Doris 中存储维度表时，可对维度表设置更多的副本，提升 Join 的性能。
  ```
* 从 Kafka 导入数据
http://doris.incubator.apache.org/documentation/cn/administrator-guide/load-data/routine-load-manual.html?highlight=kafka
