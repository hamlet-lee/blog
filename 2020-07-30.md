# DataNode 记录读写方面更详细的日志

etc/hadoop/log4j.properties
```shell
# Custom Logging levels
log4j.logger.org.apache.hadoop.hdfs.server.datanode.DataNode=DEBUG
```

则会记录类似如下LOG
```text

```

# Perf Tools
https://github.com/brendangregg/perf-tools

https://github.com/brendangregg/perf-tools/blob/master/examples/iolatency_example.txt
https://github.com/brendangregg/perf-tools/blob/master/examples/cachestat_example.txt
```
# ./iolatency -Q
Tracing block I/O. Output every 1 seconds. Ctrl-C to end.

  >=(ms) .. <(ms)   : I/O      |Distribution                          |
       0 -> 1       : 1913     |######################################|
       1 -> 2       : 438      |#########                             |
       2 -> 4       : 100      |##                                    |
       4 -> 8       : 145      |###                                   |
       8 -> 16      : 43       |#                                     |
      16 -> 32      : 43       |#                                     |
      32 -> 64      : 1        |#                                     |
      
      
# ./cachestat -t
Counting cache functions... Output every 1 seconds.
TIME         HITS   MISSES  DIRTIES    RATIO   BUFFERS_MB   CACHE_MB
08:28:57      415        0        0   100.0%            1        191
08:28:58      411        0        0   100.0%            1        191
08:28:59      362       97        0    78.9%            0          8
08:29:00      411        0        0   100.0%            0          9
08:29:01      775    20489        0     3.6%            0         89
08:29:02      411        0        0   100.0%            0         89
08:29:03     6069        0        0   100.0%            0         89
08:29:04    15249        0        0   100.0%            0         89
08:29:05      411        0        0   100.0%            0         89
08:29:06      411        0        0   100.0%            0         89
08:29:07      411        0        3   100.0%            0         89
[...]

```



# hedge read - 多读方式
https://community.cloudera.com/t5/Support-Questions/How-to-make-data-read-faster-in-HDFS/td-p/117554
```
In the meanwhile, if the read is "position read", i.e., the read is called through API read(long, byte[], int, int), you can enable hedge read in DFSClient by setting the configuration "dfs.client.hedged.read.threadpool.size" to a non-zero number. Hedge read allows the reader to start reading from another DataNode (since there are usually 3 replicas) before the first read attempt finishes, if the reader thinks the first DataNode it read from is slow.
```

```
<property>
  <name>dfs.client.hedged.read.threadpool.size</name>
  <value>20</value>
</property>
 
<property>
  <name>dfs.client.hedged.read.threshold.millis</name>
  <value>10</value>
</property>
```
