# DataNode 性能相关调研

## threads 相关参数
https://stackoverflow.com/questions/38801888/threads-in-hadoop

> dfs.datanode.handler.count is the handler threads for ClientDatanodeProtocol, which is used for client/DN RPC communicates information about block recovery meta info. The message size is small and the transfer is fast, the handler will be idle for most of the time, so we don't need much handlers. We can easily reuse the idle one. So the default value is 10 which is quite smaller than transfer.threads.

> dfs.datanode.max.transfer.threads is the number of DataXceiver threads, which is used for transfering blocks via the DTP (data transfer protocol). The block data is big and the transfer takes some time. 1 thread will be served for one block reading. only until the whole block is transferred, the thread can be reused. If there's many clients request block at the same time, we need more threads. For each write connection, there will be 2 threads. So this number should be larger for write bound applications.

> Actually DataXceiver threads will be blocked waiting for reading from disk or waiting for sending data through interface. So it doesn't consume much cpu except data checksums computation.


## datanode log
* duration 单位是 nanoseconds 即  10e-9 sec.
* https://issues.apache.org/jira/browse/HDFS-11211
```
2020-07-22 23:40:02,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /xxx:35962, dest: /xxx:xx, bytes: 953, op: HDFS_WRITE, cliID: DFSClient_attempt_15949080600261_24443_r_000027_0_59350337_58, offset: 0, srvID: 11e6a723-c06e-46a9-afb3-xxx, blockid: BP-2019197572-10.168.32.1-xxx:blk_2075069058_xxx, duration: 21504663

```

## timeout 相关 参数和报错
* https://blog.csdn.net/dehu_zhou/article/details/81533802
* datanode 读写超时时间设定, https://blog.csdn.net/dehu_zhou/article/details/81533802
hdfs客户端的读写超时时间
```
dfs.client.socket-timeout(默认60000)
dfs.datanode.socket.write.timeout(默认80000)
```

# Git clone branch
```
 git clone -b rel/release-2.7.2 git@github.com:apache/hadoop.git
```
