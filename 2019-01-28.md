# HDFS 单机故障导致集群故障
* 故障：一台运行着journal node和yarn resource manager的机器挂了，然后很多job都卡住，然后失败
* 分析：

1. resource manager 是 HA的，journal node 也是 HA 的，不应该挂掉一台就出错
1. 检查日志，发现卡在job history的请求上
1. 查看job history的日志，发现他在请求一台旧的name node并且失败

* 结论：
    之前换了一台name node机器，并修改了配置文件中的name node机器地址。但没有重启History Server。如今，它无法找到目前active的name node，从而卡住
* 解决：
    重启History Server
* 教训：
    没有想到History Server也依赖HDFS，换resource manager后没有重启它，导致它的配置没有更新
 

# JournalNode 迁移办法

参考： https://community.cloudera.com/t5/Cloudera-Manager-Installation/Journal-Node-Sync-moving-to-new-machine/m-p/47232

```
Otherwise, if you can bring down HDFS, you can do the following:

1. Stop HDFS service

2. Copy over JN edits from a (good) JN to the (bad) JN. Make sure you get all edits from all dirs (

dfs.journalnode.edits.dir)
3. Start HDFS service
 
Let me know if that works for you.
```

# Hadoop 服务启动停止
参考： https://acadgild.com/blog/hadoop-daemons

```
Namenode:

Start:hadoop-daemon.sh start namenode

stop:hadoop-daemon.sh stop namenode

Datanode:

Start:hadoop-daemon.sh start datanode

Stop:hadoop-daemon.sh stop datanode

Resource manager:

start:yarn-daemon.sh start resourcemanager

stop:yarn-daemon.sh stop resoucemnager

Node manager:

start:yarn-daemon.sh start nodemanager

stop:yarn-daemon.sh stop nodemanager

-- 以下是我补充的

History Server:
start: sbin/mr-jobhistory-daemon.sh start historyserver

Journal Node: 
start: sbin/hadoop-daemon.sh start journalnode

ZKFC (on namenode host):
start: sbin/hadoop-daemon.sh start zkfc
```
