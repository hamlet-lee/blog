# 用Fiddler调试presto通讯的方法
1. Fiddler 配置好proxy方式
1. JDBC连接串：
```properties
sql.presto.connStr=jdbc:presto://myhost:myport/hive?httpProxy=localhost:8888
```

# Presto语法的坑
```sql
select * from t1 join t2 on t1.id = t2.id;
```
这个语句执行不会报错，但相应的列名会出现两次。
如果转化为JSON，可能就会导致奇怪的数据不一致问题。
例如，t1.n1 和 t2.n1 两个列都存在，而且值不同的时候，生成的JSON可能就会只含其中一边的n1。

但如果你创建表的时候，不解决列名冲突，presto就会报错了
```sql
create table t3 as 
  select * from t1 join t2 on t1.id = t2.id;
```

# Druid disable 和 enable 的接口
based on 版本 491f8cca8 (on master)
在 enable-0.0.1.js 发现
```javascript
 $("#disable_dialog").dialog({
    autoOpen: false,
    modal:true,
    resizeable: false,
    buttons: {
      Yes : function() {
        var selected = $('#datasources option:selected').text();
        $.ajax({
          type: 'DELETE',
          url:'/druid/coordinator/v1/datasources/' + selected,
          data: JSON.stringify(selected),
          contentType:"application/json; charset=utf-8",
          dataType:"text",
          error: function(xhr, status, error) {
            $("#disable_dialog").dialog("close");
            $("#error_dialog").html(xhr.responseText);
            $("#error_dialog").dialog("open");
          },
          success: function(data, status, xhr) {
            $("#disable_dialog").dialog("close");
          }
        });
      },
      Cancel: function() {
        $(this).dialog("close");
      }
    }
  });
  
  
  $("#enable_dialog").dialog({
      autoOpen: false,
      modal:true,
      resizeable: false,
      buttons: {
        Yes : function() {
          var selected = $('#datasources option:selected').text();
          $.ajax({
            type: 'POST',
            url:'/druid/coordinator/v1/datasources/' + selected,
            data: JSON.stringify(selected),
            contentType:"application/json; charset=utf-8",
            dataType:"text",
            error: function(xhr, status, error) {
              $("#enable_dialog").dialog("close");
              $("#error_dialog").html(xhr.responseText);
              $("#error_dialog").dialog("open");
            },
            success: function(data, status, xhr) {
              $("#enable_dialog").dialog("close");
            }
          });
        },
        Cancel: function() {
          $(this).dialog("close");
        }
      }
  });
  
  $("#enable").click(function() {
    $("#enable_dialog").dialog("open");
  });
  
  $('#disable').click(function (){
    $("#disable_dialog").dialog("open")
  });
```

界面上尝试disable一个datasource "myds"，结果HTTP请求如下

```text
DELETE http://myhost:myport/druid/coordinator/v1/datasources/myds
Host: myhost:myport
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0
Accept: application/json, text/plain, */*
Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
Accept-Encoding: gzip, deflate
Connection: keep-alive
Referer: http://myhost:myport/
```

尝试enable一个datasource "myds"，结果HTTP 请求如下
```text
POST http://myhost:myport/druid/coordinator/v1/datasources/myds
Host: myhost:myport
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0
Accept: application/json, text/plain, */*
Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
Accept-Encoding: gzip, deflate
Connection: keep-alive
Referer: http://myhost:myport/
Content-Length: 0
```

代码中查找“/druid/coordinator/v1/metadata”  
找到 DatasourcesResource.java  

然后找到相应逻辑  
disable的逻辑
```java
public boolean removeDatasource(final String ds)
  {
    try {
      final int removed = connector.getDBI().withHandle(
          handle -> handle.createStatement(
              StringUtils.format("UPDATE %s SET used=false WHERE dataSource = :dataSource", getSegmentsTable())
          ).bind("dataSource", ds).execute()
      );

      dataSourcesRef.get().remove(ds);

      if (removed == 0) {
        return false;
      }
    }
    catch (Exception e) {
      log.error(e, "Error removing datasource %s", ds);
      return false;
    }

    return true;
  }
```

enable 的逻辑
```java

  @Override
  public boolean enableDatasource(final String ds)
  {
    try {
      final IDBI dbi = connector.getDBI();
      VersionedIntervalTimeline<String, DataSegment> segmentTimeline = connector.inReadOnlyTransaction(
          new TransactionCallback<VersionedIntervalTimeline<String, DataSegment>>()
          {
            @Override
            public VersionedIntervalTimeline<String, DataSegment> inTransaction(
                Handle handle, TransactionStatus status
            ) throws Exception
            {
              return handle
                  .createQuery(StringUtils.format(
                      "SELECT payload FROM %s WHERE dataSource = :dataSource",
                      getSegmentsTable()
                  ))
                  .setFetchSize(connector.getStreamingFetchSize())
                  .bind("dataSource", ds)
                  .map(ByteArrayMapper.FIRST)
                  .fold(
                      new VersionedIntervalTimeline<String, DataSegment>(Ordering.natural()),
                      new Folder3<VersionedIntervalTimeline<String, DataSegment>, byte[]>()
                      {
                        @Override
                        public VersionedIntervalTimeline<String, DataSegment> fold(
                            VersionedIntervalTimeline<String, DataSegment> timeline,
                            byte[] payload,
                            FoldController foldController,
                            StatementContext statementContext
                        ) throws SQLException
                        {
                          try {
                            final DataSegment segment = DATA_SEGMENT_INTERNER.intern(jsonMapper.readValue(
                                payload,
                                DataSegment.class
                            ));

                            timeline.add(
                                segment.getInterval(),
                                segment.getVersion(),
                                segment.getShardSpec().createChunk(segment)
                            );

                            return timeline;
                          }
                          catch (Exception e) {
                            throw new SQLException(e.toString());
                          }
                        }
                      }
                  );
            }
          }
      );

      final List<DataSegment> segments = Lists.newArrayList();
      List<TimelineObjectHolder<String, DataSegment>> timelineObjectHolders = segmentTimeline.lookup(
          Intervals.of("0000-01-01/3000-01-01")
      );
      for (TimelineObjectHolder<String, DataSegment> objectHolder : timelineObjectHolders) {
        for (PartitionChunk<DataSegment> partitionChunk : objectHolder.getObject()) {
          segments.add(partitionChunk.getObject());
        }
      }

      if (segments.isEmpty()) {
        log.warn("No segments found in the database!");
        return false;
      }

      dbi.withHandle(
          new HandleCallback<Void>()
          {
            @Override
            public Void withHandle(Handle handle) throws Exception
            {
              Batch batch = handle.createBatch();

              for (DataSegment segment : segments) {
                batch.add(
                    StringUtils.format(
                        "UPDATE %s SET used=true WHERE id = '%s'",
                        getSegmentsTable(),
                        segment.getIdentifier()
                    )
                );
              }
              batch.execute();

              return null;
            }
          }
      );
    }
    catch (Exception e) {
      log.error(e, "Exception enabling datasource %s", ds);
      return false;
    }

    return true;
  }

```
